# ü§ñ ChatRAG: Converse com seus Documentos

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=LangChain&logoColor=white)
![Groq](https://img.shields.io/badge/Groq-Fast_Inference-orange?style=for-the-badge)

**ChatRAG** √© uma aplica√ß√£o RAG (Retrieval-Augmented Generation) "Simples & R√°pida" constru√≠da com Python. Ela permite que usu√°rios fa√ßam upload de m√∫ltiplos documentos PDF e conversem com eles utilizando LLMs de √∫ltima gera√ß√£o via **Groq** (Llama 3, Mixtral, etc.), mantendo o contexto da conversa.

O projeto √© estruturado utilizando princ√≠pios de **POO (Programa√ß√£o Orientada a Objetos)** e padr√µes modernos do **LangChain (LCEL)** para robustez e escalabilidade.

**Acesse o projeto clicando [aqui](https://lelis-chatrag.streamlit.app/)**

---

## ‚ú® Funcionalidades Principais

* **Suporte Multi-PDF**: Fa√ßa upload e indexe v√°rios arquivos PDF simultaneamente.
* **Indexa√ß√£o Incremental**: Adicione novos documentos ao contexto existente sem precisar reprocessar tudo do zero.
* **Chat Contextual**: A IA lembra dos turnos anteriores da conversa (Hist√≥rico do Chat) para responder perguntas de acompanhamento com precis√£o.
* **Infer√™ncia R√°pida**: Utiliza a API da Groq para respostas quase instant√¢neas.
* **Busca Vetorial Local**: Utiliza **FAISS** para armazenamento e recupera√ß√£o eficiente de vetores na CPU.
* **Gerenciamento de Mem√≥ria**: Controles simples na interface para resetar o contexto e o hist√≥rico do chat.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Front-end**: [Streamlit](https://streamlit.io/)
* **Orquestra√ß√£o**: [LangChain](https://langchain.com/) (Core, Community, Groq)
* **Provedor de LLM**: [Groq](https://groq.com/)
* **Banco Vetorial**: [FAISS](https://github.com/facebookresearch/faiss) (Vers√£o CPU)
* **Embeddings**: [HuggingFace](https://huggingface.co/) (`BAAI/bge-m3` ou similar)
* **Gerenciador de Pacotes**: [uv](https://github.com/astral-sh/uv) (Recomendado) ou pip

---

## üìÇ Estrutura do Projeto

```text
ChatRAG/
‚îú‚îÄ‚îÄ .env                  # Configura√ß√£o das Chaves de API
‚îú‚îÄ‚îÄ .python-version       # Arquivo de vers√£o do Python
‚îú‚îÄ‚îÄ pyproject.toml        # Depend√™ncias (uv)
‚îú‚îÄ‚îÄ README.md             # Documenta√ß√£o do projeto
‚îú‚îÄ‚îÄ uv.lock               # Arquivo de sincroniza√ß√£o do uv (Versionamento de pacotes)
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ app.py            # Ponto de entrada (Frontend Streamlit)
    ‚îú‚îÄ‚îÄ controller.py     # Orquestrador (L√≥gica RAG & Gerenciamento de Estado)
    ‚îî‚îÄ‚îÄ modules/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ llm_factory.py    # F√°brica para modelos de LLM e Embeddings
        ‚îú‚îÄ‚îÄ pdf_loader.py     # L√≥gica de processamento e chunking de PDF
        ‚îî‚îÄ‚îÄ vector_db.py      # Gerenciamento do FAISS Vector Store
```

---

## üß† Vis√£o da Arquitetura

O projeto segue um padr√£o limpo de Controller-Service:

- `app.py`: Lida com a renderiza√ß√£o da UI e gerenciamento do Estado da Sess√£o (`st.session_state`). Delega toda a l√≥gica para o Controller.

- `controller.py`: O c√©rebro da opera√ß√£o. Inicializa os m√≥dulos e constr√≥i o pipeline LangChain LCEL:

    - Input -> Retriever + Hist√≥rico -> Prompt -> LLM -> Output.

- `vector_db.py`: Gerencia o FAISS. Suporta `create_from_documents` (sobrescrever) e `add_documents` (atualiza√ß√£o incremental).

- `pdf_loader.py`: Lida com arquivos tempor√°rios, carregamento via `PyPDFLoader` e divis√£o de texto usando `RecursiveCharacterTextSplitter`.

---

## üìù Licen√ßa

Este projeto √© para fins educacionais. Sinta-se √† vontade para modificar e usar como desejar.