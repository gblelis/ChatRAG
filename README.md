# ü§ñ ChatRAG: Converse com seus Documentos

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=LangChain&logoColor=white)
![Groq](https://img.shields.io/badge/Groq-Fast_Inference-orange?style=for-the-badge)

**ChatRAG** √© uma aplica√ß√£o RAG (Retrieval-Augmented Generation) constru√≠da com Python. Ela permite que usu√°rios fa√ßam upload de m√∫ltiplos documentos PDF e conversem com eles utilizando LLMs via **Groq**, mantendo o contexto da conversa.

O projeto √© estruturado utilizando princ√≠pios de **POO (Programa√ß√£o Orientada a Objetos)** e padr√µes modernos do **LangChain (LCEL)** para robustez e escalabilidade.

<img width="1919" height="1079" alt="image" src="https://github.com/user-attachments/assets/c96ad8c8-114b-4589-94c7-320e5a786740" />

---

## ‚ú® Funcionalidades Principais

* **Suporte Multi-PDF**: Fa√ßa upload e indexe v√°rios arquivos PDF simultaneamente.
* **Indexa√ß√£o Incremental**: Adicione novos documentos ao contexto existente sem precisar reprocessar tudo do zero.
* **Chat Contextual**: A IA lembra dos turnos anteriores da conversa (Hist√≥rico do Chat) para responder perguntas de acompanhamento com precis√£o.
* **Infer√™ncia R√°pida**: Utiliza a API da Groq para respostas quase instant√¢neas.
* **Busca Vetorial Local**: Utiliza **FAISS** para armazenamento e recupera√ß√£o eficiente de vetores na CPU.
* **Gerenciamento de Mem√≥ria**: Controles simples na interface para resetar o contexto e o hist√≥rico do chat.

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Front-end**: [Streamlit](https://streamlit.io/)
* **Orquestra√ß√£o**: [LangChain](https://langchain.com/) (Core, Community, Groq)
* **Provedor de LLM**: [Groq](https://groq.com/)
* **Banco Vetorial**: [FAISS](https://github.com/facebookresearch/faiss) (Vers√£o CPU)
* **Embeddings**: [HuggingFace](https://huggingface.co/) (`BAAI/bge-m3`)
* **Gerenciador de Pacotes**: [uv](https://github.com/astral-sh/uv) (Recomendado) ou pip

---

## üìÇ Estrutura do Projeto

```text
ChatRAG/
‚îú‚îÄ‚îÄ .env                  # Configura√ß√£o das Chaves de API
‚îú‚îÄ‚îÄ .python-version       # Arquivo de vers√£o do Python
‚îú‚îÄ‚îÄ pyproject.toml        # Depend√™ncias (uv)
‚îú‚îÄ‚îÄ README.md             # Documenta√ß√£o do projeto
‚îú‚îÄ‚îÄ requirements.txt      # Requisitos de pacotes do python
‚îú‚îÄ‚îÄ uv.lock               # Arquivo de sincroniza√ß√£o do uv (Versionamento de pacotes)
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ app.py            # Ponto de entrada (Frontend Streamlit)
    ‚îú‚îÄ‚îÄ controller.py     # Orquestrador (L√≥gica RAG & Gerenciamento de Estado)
    ‚îî‚îÄ‚îÄ modules/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ llm_factory.py    # F√°brica para modelos de LLM e Embeddings
        ‚îú‚îÄ‚îÄ pdf_loader.py     # L√≥gica de processamento e chunking de PDF
        ‚îî‚îÄ‚îÄ vector_db.py      # Gerenciamento do FAISS Vector Store
```

---

## üöÄ Como Iniciar

### Pr√©-requisitos:

1. Python 3.10 instalado.

2. Groq API Key: Obtenha uma gratuitamente em [console.groq.com](console.groq.com).

3. (Opcional) `uv` instalado para gerenciamento r√°pido de depend√™ncias.

### Instala√ß√£o:

1. Clone o reposit√≥rio:

```bash
git clone https://github.com/gblelis/ChatRAG.git
cd ChatRAG
```

2. Instale as Depend√™ncias:

- Usando `uv` (Recomendado):

```bash
uv sync
```

- Usando `pip` padr√£o:

```bash
pip install -r requirements.txt
```

3. Configure o Ambiente: Crie um arquivo `.env` na raiz do projeto:

```bash
GROQ_API_KEY=gsk_sua_chave_aqui
```

## ‚ñ∂Ô∏è Como Usar

Rode a aplica√ß√£o usando o Streamlit:

```bash
# Usando uv
uv run streamlit run src/app.py

# Ou usando python padr√£o
streamlit run src/app.py
```

O app abrir√° no seu navegador em `http://localhost:8501`.

1. **Upload**: Use a barra lateral para carregar um ou m√∫ltiplos arquivos PDF.

2. **Adicionar** ao Contexto: Clique em "Add PDFs to context" para indexar o conte√∫do.

3. **Chat**: Digite suas perguntas no campo principal. A IA responder√° baseada apenas nos documentos fornecidos.

4. **Limpar**: Use o bot√£o de lixeira na barra lateral para limpar a mem√≥ria e come√ßar do zero.

---

## üß† Vis√£o da Arquitetura

O projeto segue um padr√£o limpo de Controller-Service:

- `app.py`: Lida com a renderiza√ß√£o da UI e gerenciamento do Estado da Sess√£o (`st.session_state`). Delega toda a l√≥gica para o Controller.

- `controller.py`: O c√©rebro da opera√ß√£o. Inicializa os m√≥dulos e constr√≥i o pipeline LangChain LCEL:

    - Input -> Retriever + Hist√≥rico -> Prompt -> LLM -> Output.

- `vector_db.py`: Gerencia o FAISS. Suporta `create_from_documents` (sobrescrever) e `add_documents` (atualiza√ß√£o incremental).

- `pdf_loader.py`: Lida com arquivos tempor√°rios, carregamento via `PyPDFLoader` e divis√£o de texto usando `RecursiveCharacterTextSplitter`.

---

## üìù Licen√ßa

MIT License ¬© 2025 Gabriel Lelis